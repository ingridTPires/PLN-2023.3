{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ingridTPires/PLN-2023.3/blob/main/2023_Q3_PLN_ATIVIDADE_PR%C3%81TICA_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2023.Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **ATIVIDADE PRÁTICA 02 [Extração e Pré-processamento de Dados + Expressões Regulares]**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk0nHKabBT-"
      },
      "source": [
        "A **ATIVIDADE PRÁTICA 02** deve ser feita utilizando o **Google Colab** com uma conta\n",
        "sua vinculada ao Gmail. O link do seu notebook, armazenado no Google Drive, além do link de um repositório no GitHub e os principais resultados da atividade, devem ser enviados usando o seguinte formulário:\n",
        "\n",
        "> https://forms.gle/83JggUJ1mhgWviEaA\n",
        "\n",
        "\n",
        "**IMPORTANTE**: A submissão deve ser feita até o dia 16/10 (segunda-feira) APENAS POR UM INTEGRANTE DA EQUIPE, até às 23h59. Por favor, lembre-se de dar permissão de ACESSO IRRESTRITO para o professor da disciplina de PLN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gbHxmzJEORRh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01:**\n",
        "\n",
        "`Por favor, informe o seu nome completo e RA:` David Oliveira Silva -  11201721357\n",
        "\n",
        "**Integrante 02:**\n",
        "\n",
        "`Por favor, informe o seu nome completo e RA:` Ingrid Teixeira Pires - 11201812175\n",
        "\n",
        "**Integrante 03:**\n",
        "\n",
        "`Por favor, informe o seu nome completo e RA:` Bruno Delphini Fontanezi - 11202130336"
      ],
      "metadata": {
        "id": "tnIArN0QY-Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LIVRO**\n",
        "---"
      ],
      "metadata": {
        "id": "6yExhaebs-nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português.`\n",
        "\n",
        ">\n",
        "\n",
        "Disponível gratuitamente em:\n",
        "  \n",
        "  > https://brasileiraspln.com/livro-pln/1a-edicao/.\n",
        "\n",
        "\n",
        "**POR FAVOR, PREENCHER OS CAPITULOS SELECIONADOS PARA A SUA EQUIPE:**\n",
        "\n",
        "`Primeiro capítulo: ` 5\n",
        "\n",
        "`Segundo capítulo:` 21\n",
        "\n"
      ],
      "metadata": {
        "id": "DjJM_qhEZRy6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRIÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementar um `notebook` no `Google Colab` para identificar ERROS em 2 (DOIS) capítulos do livro **Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português**.\n",
        "\n",
        "Os capítulos devem ser selecionados na seguinte planilha:\n",
        "\n",
        "https://docs.google.com/spreadsheets/d/1ZutzQ3v1OJgsgzCvCwxXlRIQ3ChXNlHNvB63JQvYsbo/edit?usp=sharing\n",
        "\n",
        ">\n",
        "\n",
        "**IMPORTANTE:** É obrigatório usar o e-mail da UFABC.\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "**DICA:** Por favor, insira o seu nome ou da sua equipe na ordem definida na planilha. Por exemplo, se a linha correspondente ao o GRUPO 5 já foi preenchida, a próxima equipe (GRUPO 6) deverá ser informada na próxima linha da planilha.\n",
        "\n"
      ],
      "metadata": {
        "id": "fXTwkiiGs2BV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TIPOS DE ERROS**\n",
        "---\n"
      ],
      "metadata": {
        "id": "eD_AJQhrwJQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE**: consulta feita no ChatGPT\n",
        ">\n",
        "\n",
        "Um `programa Python` que utilize `expressões regulares` pode ajudar a identificar vários **tipos de erros** comuns em **livros**, especialmente erros de formatação e problemas relacionados à consistência do texto. Aqui estão alguns exemplos de erros comuns que podem ser identificados usando expressões regulares:\n",
        "\n",
        "* Erros de gramática e ortografia: erros de digitação, concordância verbal e nominal, uso incorreto de pontuação e outros erros gramaticais.\n",
        "\n",
        "* Problemas de formatação: você pode usar expressões regulares para encontrar erros de formatação, como espaços em excesso, tabulações inadequadas ou alinhamentos inconsistentes.\n",
        "\n",
        "* Abreviações e acrônimos: você pode usar expressões regulares para encontrar abreviações ou acrônimos que não foram definidos ou explicados anteriormente no texto.\n",
        "\n",
        "* Citações e referências: expressões regulares podem ser úteis para localizar citações ou referências que precisam de formatação especial.\n",
        "\n",
        "* OUTROS TIPOS DE ERROS: não considerem apenas os tipos de erros citados acima.\n",
        "\n",
        "\n",
        "**IMPORTANTE:** Lembre-se de que expressões regulares podem ser poderosas, mas também complexas. Dependendo da complexidade dos erros que você deseja identificar, pode ser necessário ajustar as expressões regulares de acordo com as características específicas do seu texto. Além disso, é importante ter em mente que as expressões regulares podem não ser a melhor ferramenta para todos os tipos de erros em livros, especialmente problemas mais contextuais ou semânticos, que podem exigir abordagens de PLN mais avançadas.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gz0DTI0KYmn6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CRITÉRIOS DE AVALIAÇÃO**\n",
        "---\n"
      ],
      "metadata": {
        "id": "gWsBYQNtxmum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A equipe que **realizar mais testes** e/ou **identificar mais erros** terá o peso diminuido na AVALIAÇÃO (Prova Escrita) em **25%** (caindo de 40 para 30). Os testes e possíveis erros devem ser contabizados de maneira separada.\n",
        "\n",
        ">\n",
        "\n",
        "Além disso, **por se tratar de um livro**, há um teste importante que deve ser feito. Lembre-se que o teste deve ser feito utilizando expressões regulares. A equipe que realizar esse teste, mesmo que o erro não ocorra nos capítulos selecionados, terá o peso diminuido na AVALIAÇÃO (Prova Escrita) em **25%** (caindo de 40 para 30).\n",
        "\n",
        "> A equipe pode considerar outros capítulos do livro para tentar identificar esse tipo de erro.\n",
        "\n",
        "**Se for a mesma equipe, o peso da avaliação será reduzido em 50% (caindo de 40 para 20)**.\n",
        "\n",
        ">\n",
        "\n",
        "**IMPORTANTE**: a diminuição no peso da AVALIAÇÃO será aplicado para todos os membros da equipe. Esse critério será aplicado apenas para uma equipe, considerando como critério de desempate a equipe que entregar primeiro a atividade no formulário.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5iHdx4BXYruQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPLEMENTAÇÃO**\n",
        "---"
      ],
      "metadata": {
        "id": "nw09lujGvfjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "def extrair_texto_de_todas_as_secoes(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "    # Encontre todas as tags <section> e extraia o texto de cada uma delas\n",
        "    sections = soup.find_all('section')\n",
        "    texts = [section.get_text() for section in sections]\n",
        "\n",
        "    # Junte todos os textos em uma única string\n",
        "    combined_text = '\\n'.join(texts)\n",
        "\n",
        "    return combined_text\n"
      ],
      "metadata": {
        "id": "RyUailD5vi9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extrair_e_analisar_erros(text):\n",
        "\n",
        "    # Encontrar erros de pontuação\n",
        "    expressao_pontuacao = r'[^\\s]\\s+[.,!?;]'\n",
        "    erros_pontuacao = re.findall(expressao_pontuacao, text)\n",
        "\n",
        "    # Encontrar abreviações/acrônimos não definidos\n",
        "    expressao_abreviacoes = r'\\b[A-Z]{2,}\\b'\n",
        "    erros_abreviacoes = re.findall(expressao_abreviacoes, text)\n",
        "    abreviacoes_unicas = set(erros_abreviacoes)\n",
        "\n",
        "    # Verificação de citações\n",
        "    expressao_citacoes = r'\\b\"[^\"]+\"\\s*\\(.*\\)'\n",
        "    erros_citacoes = re.findall(expressao_citacoes, text)\n",
        "\n",
        "    # Encontrar erros de hifenização\n",
        "    expressao_hifens = r'\\w+-\\w+'\n",
        "    erros_hifens = re.findall(expressao_hifens, text)\n",
        "    erros_hifens_unicos = set(erros_hifens)\n",
        "\n",
        "    # Valida caracteres especiais\n",
        "    expressao_caracter_especial = r'[!@#%$&*]'\n",
        "    erros_caracter_especial = re.findall(expressao_caracter_especial, text)\n",
        "\n",
        "    # Verifica se há palavras repetidas.\n",
        "    expressao_palavra_repetida = r'\\s(\\S+\\s)\\1'\n",
        "    erros_palavra_repetida = re.findall(expressao_palavra_repetida, text)\n",
        "\n",
        "    # Verifica se há inconsistência em estilo de aspas.\n",
        "    expressao_aspas = r'[\"\\']'\n",
        "    erros_aspas = re.findall(expressao_aspas, text)\n",
        "\n",
        "    # Verifica se há palavra com letra maiúscula após vírgula.\n",
        "    expressao_maiuscula_virgula = r', ([A-Z][a-zA-Z]*)'\n",
        "    erros_maiuscula_virgula = re.findall(expressao_maiuscula_virgula, text)\n",
        "\n",
        "\n",
        "    expressao_espaco_duplo = r'\\w+\\s\\s\\w+'\n",
        "    erro_espaco_duplo = re.findall(expressao_espaco_duplo, text)\n",
        "\n",
        "    print(\"Erros de Pontuação:\", erros_pontuacao)\n",
        "    print(\"Abreviações/Acrônimos não definidos:\", list(abreviacoes_unicas))\n",
        "    print(\"Citações não formatadas:\", erros_citacoes)\n",
        "    print(\"Erros de hifen:\",list (erros_hifens_unicos))\n",
        "    print(\"Erros de caracteres especiais:\", erros_caracter_especial)\n",
        "    print(\"Erros de palavras repetidas: \", erros_palavra_repetida)\n",
        "    print(\"Erros de inconsistências de aspas: \", erros_aspas)\n",
        "    print(\"Erros de palavras com letra maíuscula após virgula: \", erros_maiuscula_virgula)\n",
        "    print(\"Erros de espaços duplos:\", erro_espaco_duplo)\n",
        "\n",
        "\n",
        "# URL do primeiro capítulo\n",
        "url_capitulo_5 = \"https://brasileiraspln.com/livro-pln/1a-edicao/parte3/cap5/cap5.html\"\n",
        "# URL do segundo capítulo\n",
        "url_capitulo_21 = \"https://brasileiraspln.com/livro-pln/1a-edicao/parte9/cap21/cap21.html\"\n",
        "\n",
        "print(\"Capítulo 5:\")\n",
        "texto_capitulo_5 = extrair_texto_de_todas_as_secoes(url_capitulo_5)\n",
        "extrair_e_analisar_erros(texto_capitulo_5)\n",
        "\n",
        "print(\"\\nCapítulo 21:\")\n",
        "texto_capitulo_21 = extrair_texto_de_todas_as_secoes(url_capitulo_21)\n",
        "extrair_e_analisar_erros(texto_capitulo_21)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcbptqEpJq5E",
        "outputId": "84a874eb-7871-43c1-e26b-a78661fbd67e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Capítulo 5:\n",
            "Erros de Pontuação: []\n",
            "Abreviações/Acrônimos não definidos: ['PARSEME', 'MWE', 'PLN']\n",
            "Citações não formatadas: []\n",
            "Erros de hifen: []\n",
            "Erros de caracteres especiais: ['!']\n",
            "Erros de palavras repetidas:  []\n",
            "Erros de inconsistências de aspas:  []\n",
            "Erros de palavras com letra maíuscula após virgula:  []\n",
            "Erros de espaços duplos: []\n",
            "\n",
            "Capítulo 21:\n",
            "Erros de Pontuação: []\n",
            "Abreviações/Acrônimos não definidos: ['EHR', 'SNOMED', 'YANG', 'LEE', 'FUSHMAN', 'JONES', 'GDPR', 'LGPD', 'SHICKEL', 'CEP', 'RES', 'OLIVEIRA', 'GULDEN', 'TURCHIOE', 'NLP', 'SILVA', 'DA', 'JMIR', 'CHEN', 'YAN', 'PEC', 'SHEIKHALISHAHI', 'DEMNER', 'PROPOR', 'SUS', 'DALIANIS', 'DE', 'ULBRICH', 'WU', 'VIEIRA', 'CID', 'CT', 'MCDONALD', 'PLN', 'NER', 'FENNELLY', 'GUMIEL', 'BIBM', 'MORE', 'MATTHIESSEN', 'NEAR', 'TERUYA', 'IEEE', 'NATH', 'EU', 'JIANG', 'SANTOS', 'PUCPR', 'UFMG', 'CHAPMAN', 'GUSTAD', 'LIU', 'KOLECK']\n",
            "Citações não formatadas: []\n",
            "Erros de hifen: ['bem-sucedida', 'multi-specialty', 'multi-ontology', 'pré-determinados', 'acesso-a', 'law-topic', 'Springer-Verlag', 'socio-semiótica', 'pt-br', 'corpus-based', 'Free-Text', 'Ressalta-se', 'concentra-se', 'Demner-Fushman', '030-98305', 'Depclin-Br', 'Part-of', 'general-purpose', 'De-identification', 'multi-dimensional', '4-5', 'Multi-Ontology', 'fine-tuning', 'pré-processamento', 'socio-semióticas', 'e-mail', 'busca-se', 'pre-trained', 'Trata-se', 'de-identificação', 'Meta-Evaluation', 'DEMNER-FUSHMAN', 'data-protection', 'multi-institutional', '978-3', 'free-text', 'aplica-se']\n",
            "Erros de caracteres especiais: []\n",
            "Erros de palavras repetidas:  []\n",
            "Erros de inconsistências de aspas:  []\n",
            "Erros de palavras com letra maíuscula após virgula:  ['Named', 'PoS', 'Named', 'PoS', 'A', 'D', 'H', 'D', 'W', 'C', 'O', 'T', 'Machine', 'Explainability', 'C', 'Y', 'S', 'K', 'T', 'J', 'Z', 'M', 'M', 'K', 'C', 'N', 'S', 'I', 'L', 'L', 'PROPOR', 'Fortaleza', 'Brazil', 'March', 'Proceedings', 'Heidelberg', 'H', 'A', 'R', 'J', 'S', 'B', 'A', 'M', 'H', 'M', 'L', 'H', 'Lei']\n",
            "Erros de espaços duplos: ['Saúde\\n\\n21']\n"
          ]
        }
      ]
    }
  ]
}